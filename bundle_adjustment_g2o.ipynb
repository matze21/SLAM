{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time \n",
    "import g2o \n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path='sample_data/Room_back_home-2024-12-29_19-50-26/'\n",
    "folder_path_img = folder_path+'/Camera'\n",
    "\n",
    "gyro = pd.read_csv(folder_path+'Gyroscope.csv')\n",
    "gyro['time_diff_s'] = gyro['time'].diff().fillna(0) / 1e9\n",
    "gyro['roll'] = (gyro['x']*gyro['time_diff_s']).cumsum()\n",
    "gyro['pitch'] = (gyro['y']*gyro['time_diff_s']).cumsum()\n",
    "gyro['yaw'] = (gyro['z']*gyro['time_diff_s']).cumsum()\n",
    "gyro.drop(['x','y','z'],axis=1,inplace=True)\n",
    "\n",
    "acc = pd.read_csv(folder_path+'/Accelerometer.csv')\n",
    "\n",
    "motion = pd.merge(gyro, acc, on=['time','seconds_elapsed'],how='inner')\n",
    "motion.rename(columns={'x': 'ax','y': 'ay','z': 'az'}, inplace=True)\n",
    "\n",
    "\n",
    "image_filenames = sorted(os.listdir(folder_path_img))[1:-1]\n",
    "image_timestamps = [float(filename.split('.')[0]) for filename in image_filenames] \n",
    "\n",
    "def synchronize_data(imu_data, image_timestamps):\n",
    "    synchronized_data = []\n",
    "    for img_time in image_timestamps:\n",
    "        # Find closest IMU timestamp\n",
    "        closest_imu_index = (np.abs(imu_data['time'] - img_time*1e6)).argmin()\n",
    "        synchronized_data.append({\n",
    "            'image_time': img_time,\n",
    "            'imu_roll': imu_data.iloc[closest_imu_index]['roll'],\n",
    "            'imu_pitch': imu_data.iloc[closest_imu_index]['pitch'],\n",
    "            'imu_yaw': imu_data.iloc[closest_imu_index]['yaw'],\n",
    "            'imu_ax': imu_data.iloc[closest_imu_index]['ax'],\n",
    "            'imu_ay': imu_data.iloc[closest_imu_index]['ay'],\n",
    "            'imu_az': imu_data.iloc[closest_imu_index]['az'],\n",
    "            'image_path': os.path.join(folder_path_img, image_filenames[image_timestamps.index(img_time)])\n",
    "        })\n",
    "    return pd.DataFrame(synchronized_data)\n",
    "\n",
    "synchronized_synchronized_df = synchronize_data(motion, image_timestamps)\n",
    "synchronized_synchronized_df['time_diff_s'] = synchronized_synchronized_df['image_time'].diff().fillna(0) / 1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keypoint extraction helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(img):\n",
    "    \"\"\" \n",
    "    extract features of an image\n",
    "    \"\"\"\n",
    "    orb = cv2.ORB_create()\n",
    " \n",
    "    # Detection\n",
    "    pts = cv2.goodFeaturesToTrack(np.mean(img, axis=-1).astype(np.uint8), 1000, qualityLevel=0.01, minDistance=10)\n",
    " \n",
    "    # Extract key points\n",
    "    kps = [cv2.KeyPoint(f[0][0], f[0][1], 20) for f in pts]\n",
    "    kps, des = orb.compute(img, kps)\n",
    " \n",
    "    return np.array([(kp.pt[0], kp.pt[1]) for kp in kps]), des\n",
    "\n",
    "def add_ones(x):\n",
    "    \"\"\" \n",
    "    helper function to add ones to have right format of normalized coordinates (TODO: understand better)\n",
    "    \"\"\"\n",
    "    # creates homogenious coordinates given the point x\n",
    "    return np.concatenate([x, np.ones((x.shape[0], 1))], axis=1)\n",
    "\n",
    "def normalize(Kinv, pts):\n",
    "    \"\"\"\n",
    "    transform image coordinates to normalized coordinates\n",
    "    \"\"\"\n",
    "    # The inverse camera intrinsic matrix 𝐾^(−1) transforms 2D homogeneous points \n",
    "    # from pixel coordinates to normalized image coordinates. \n",
    "    return np.dot(Kinv, add_ones(pts).T).T[:, 0:2]\n",
    "\n",
    "class Frame(object):\n",
    "    \"\"\" \n",
    "    Class that has all the frame data\n",
    "    \"\"\"\n",
    "    def __init__(self, img, K, id):\n",
    "        self.id = id   # unique identifier\n",
    "        self.K = K     # Intrinsic camera matrix\n",
    "        self.Kinv = np.linalg.inv(self.K)  # Inverse of the intrinsic camera matrix\n",
    " \n",
    "        pts, self.des = extract(img)             # Extract feature points and descriptors from the image\n",
    "        self.pts = normalize(self.Kinv, pts)     # Normalizes feature points to normalized coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keypoint matching\n",
    "option 1:\n",
    "- always match against all previous points \n",
    "- keep first descriptor pattern OR update descriptor pattern with most recent one\n",
    "- potential runtime issues -> will explode fast / limit keypoint number\n",
    "- native loop closure detection\n",
    "\n",
    "option 2:\n",
    "- only match against last 3 frames or similar\n",
    "- how to detect loop closure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniquePointsFullListMatching(object):\n",
    "    \"\"\" \n",
    "    this class tracks all unique points in entire frame, it consists of 3 index parallel lists\n",
    "    descriptor: list of unique descriptors in entire sequence\n",
    "    frameIds:   list of frame ids (list of lists), index parallel to descriptor (one descriptor multiple frame ids)\n",
    "    normPoints: list of normalized points per frame (list of lists), also index parallel to descriptor (one descriptor, multiple frames with a point per frame)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.descriptor = [] # (descriptor, [frame_ids])\n",
    "        self.frameIds   = []\n",
    "        self.normPoints = [] #normalized point per frame id\n",
    "        self.initial3dEstimates = []\n",
    "\n",
    "    def processFrame(self, f):\n",
    "        if(self.descriptor.empty()):\n",
    "            for idx, des in enumerate(f.des):\n",
    "                self.descriptor.append(des)\n",
    "                self.frameId.append([f.id])\n",
    "                self.normPoints.append([f.pts[idx]])\n",
    "        else:\n",
    "            self.calcAssociations(f)\n",
    "\n",
    "    def calcAssociations(self, f):\n",
    "        # The code performs k-nearest neighbors matching on feature descriptors\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "        matches = bf.knnMatch(np.array(self.descriptor), f.des, k=2)    \n",
    "\n",
    "        # applies Lowe's ratio test to filter out good \n",
    "        # matches based on a distance threshold.\n",
    "        ret = []\n",
    "        idx1, idx2 = [], []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.75*n.distance:\n",
    "                p1 = self.normPoints[m.queryIdx].end()  # take last measured point as most recent to determine l2 norm\n",
    "                p2 = f.pts[m.trainIdx]\n",
    "\n",
    "                # Distance test\n",
    "                # dditional distance test, ensuring that the \n",
    "                # Euclidean distance between p1 and p2 is less than 0.1\n",
    "                if np.linalg.norm((p1-p2)) < 0.1:\n",
    "                    self.associate(m.queryIdx, f.id, p2)\n",
    "                    pass  \n",
    "\n",
    "    def associate(self, uniquePtIdx, frameId, newPoint):\n",
    "        self.frameIds[uniquePtIdx].append(frameId)  # add new frameid to associated point\n",
    "        self.normPoints[uniquePtIdx].append(newPoint)  # add new normalized point to associated point\n",
    "\n",
    "    def initial3dEstimate(self):\n",
    "        #TODO, maybe not needed, \n",
    "        # do the initial easy triangulation (optimization problem)\n",
    "        # can only be done for unique points with more than 1 frame\n",
    "\n",
    "\n",
    "    # Idea: in a for loop: \n",
    "    # - track unique points: (descriptor, [frame_ids])\n",
    "    # - when processing new frame we check if we have matches to the unique points\n",
    "    # - if match to a unique point -> append frame id to unique point\n",
    "    # - otherwise append new unique point to list\n",
    "\n",
    "    # -> disadvantage (TODO), how do i update the descriptors over multiple frames? maybe not necessary\n",
    "    # -> maybe possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run association\n",
    "uniquePts = UniquePointsFullListMatching()\n",
    ".."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup graph\n",
    "- set poses as nodes (TODO: how to define edges between imu data/poses)\n",
    "- create characteristic points per frame\n",
    "- find matches between current frame and all other frames\n",
    "- add edges for common points\n",
    "\n",
    "Potential follow ups:\n",
    "- add another pose estimate through image data + edge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets optimizer \n",
    "optimizer = g2o.SparseOptimizer()\n",
    "solver = g2o.BlockSolverSE3(g2o.LinearSolverCSparseSE3())\n",
    "solver = g2o.OptimizationAlgorithmLevenberg(solver)\n",
    "optimizer.set_algorithm(solver)\n",
    "\n",
    "\n",
    "K = np.array([[730, 0, 620], [0, 730, 360], [0, 0, 1]])  # Example values\n",
    "g2o.VertexSCam.set_cam(*K)\n",
    "\n",
    "# Create vertices from cameras\n",
    "for idx_extr, extrinsic in enumerate(extrinsics):\n",
    "    pose = g2o.Isometry3d(np.linalg.inv(extrinsic))\n",
    "    v_se3 = g2o.VertexSCam()\n",
    "    v_se3.set_id(idx_extr)\n",
    "    v_se3.set_estimate(pose)\n",
    "    v_se3.set_fixed(False)\n",
    "    v_se3.set_all() # Calculates matrices related to projection\n",
    "    optimizer.add_vertex(v_se3)\n",
    "\n",
    "# Each vertex must have a unique id. \n",
    "# Ensure point and camera ids do not overlap.\n",
    "last_pose_id = idx_extr\n",
    "first_point_id = last_pose_id + 1\n",
    "\n",
    "# Create vertices from all points and connect them to the cameras\n",
    "for idx, des in enumerate(uniquePts.descriptor):\n",
    "    point_id = idx + first_point_id\n",
    "    \n",
    "    # Create a point vertex with distorted estimate\n",
    "    vertex_point = g2o.VertexSBAPointXYZ()\n",
    "    vertex_point.set_id(point_id)\n",
    "    # see https://github.com/RainerKuemmerle/g2o/issues/109 on why we use this\n",
    "    vertex_point.set_marginalized(True)  \n",
    "    vertex_point.set_estimate(distorted_point) #I guess estimated 3d position, maybe I can set it to 1,0,0 or pose estimate\n",
    "    optimizer.add_vertex(vertex_point)\n",
    "    \n",
    "    # Create an point-camera edge with each camera\n",
    "    for idxAssocPt, projected_point in enumerate(uniquePts.normPoints[idx]):\n",
    "        frameId = uniquePts.frameIds[idx][idxAssocPt] # from the current unique point get the frame id that we're just processing\n",
    "        cameraPoseId = frameId # need to ensure this is true\n",
    "        edge = g2o.Edge_XYZ_VSC()\n",
    "        edge.set_vertex(0, vertex_point) \n",
    "        edge.set_vertex(1, optimizer.vertex(cameraPoseId))\n",
    "        edge.set_measurement(projected_point) \n",
    "        # The information matrix is the measurement \n",
    "        # uncertainty. We set this equal for all measurements.\n",
    "        edge.set_information(np.identity(3))\n",
    "        edge.set_parameter_id(0, 0)\n",
    "        optimizer.add_edge(edge)\n",
    "    last_point_id = point_id\n",
    "\n",
    "optimizer.initialize_optimization()\n",
    "optimizer.set_verbose(False)\n",
    "print(\"g2o graph has been created\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
