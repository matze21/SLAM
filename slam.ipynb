{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graphslam.graph import Graph\n",
    "from graphslam.vertex import Vertex\n",
    "from graphslam.edge.edge_odometry import EdgeOdometry\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader:\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.image_files = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
    "        self.image_files.sort()  # Ensure images are in order\n",
    "        self.current_index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_index >= len(self.image_files):\n",
    "            raise StopIteration\n",
    "        \n",
    "        image_path = os.path.join(self.folder_path, self.image_files[self.current_index])\n",
    "        image = cv2.imread(image_path)\n",
    "        self.current_index += 1\n",
    "        return image\n",
    "\n",
    "# Usage\n",
    "folder_path = 'sample_data/Room_back_home-2024-12-29_19-50-26/Camera'\n",
    "image_loader = ImageLoader(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyro = pd.read_csv('/Users/matthiaskargl/Codes/SLAM/sample_data/2024-11-09_15-06-37/Gyroscope.csv')\n",
    "gyro['time_diff_s'] = gyro['time'].diff().fillna(0) / 1e9\n",
    "gyro['roll'] = (gyro['x']*gyro['time_diff_s']).cumsum()\n",
    "gyro['pitch'] = (gyro['y']*gyro['time_diff_s']).cumsum()\n",
    "gyro['yaw'] = (gyro['z']*gyro['time_diff_s']).cumsum()\n",
    "gyro.drop(['x','y','z'],axis=1,inplace=True)\n",
    "\n",
    "acc = pd.read_csv('/Users/matthiaskargl/Codes/SLAM/sample_data/2024-11-09_15-06-37/Accelerometer.csv')\n",
    "\n",
    "motion = pd.merge(gyro, acc, on=['time','seconds_elapsed'],how='inner')\n",
    "motion.rename(columns={'x': 'ax','y': 'ay','z': 'az'}, inplace=True)\n",
    "motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1731164816467        in ms\n",
    "#1731164816433211400  in ns\n",
    "image_filenames = sorted(os.listdir(folder_path)) \n",
    "image_timestamps = [float(filename.split('.')[0]) for filename in image_filenames] \n",
    "\n",
    "def synchronize_data(imu_data, image_timestamps):\n",
    "    synchronized_data = []\n",
    "    for img_time in image_timestamps:\n",
    "        # Find closest IMU timestamp\n",
    "        closest_imu_index = (np.abs(imu_data['time'] - img_time*1e6)).argmin()\n",
    "        synchronized_data.append({\n",
    "            'image_time': img_time,\n",
    "            'imu_roll': imu_data.iloc[closest_imu_index]['roll'],\n",
    "            'imu_pitch': imu_data.iloc[closest_imu_index]['pitch'],\n",
    "            'imu_yaw': imu_data.iloc[closest_imu_index]['yaw'],\n",
    "            'imu_ax': imu_data.iloc[closest_imu_index]['ax'],\n",
    "            'imu_ay': imu_data.iloc[closest_imu_index]['ay'],\n",
    "            'imu_az': imu_data.iloc[closest_imu_index]['az'],\n",
    "            'image_path': os.path.join(folder_path, image_filenames[image_timestamps.index(img_time)])\n",
    "        })\n",
    "    return pd.DataFrame(synchronized_data)\n",
    "\n",
    "synchronized_df = synchronize_data(motion, image_timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synchronized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define slam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pose Estimation with IMU Integration\n",
    "def compute_pose(prev_keypoints, prev_descriptors, curr_keypoints, curr_descriptors, i):\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = matcher.match(prev_descriptors, curr_descriptors)\n",
    "\n",
    "    # Filter matches to get only good matches\n",
    "    good_matches = [m for m in matches if m.distance < 50]  # Adjust threshold as necessary\n",
    "\n",
    "    if len(good_matches) < 5:\n",
    "        print(\"Not enough matches found.\",i)\n",
    "        return None, None\n",
    "\n",
    "    src_pts = np.float32([prev_keypoints[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([curr_keypoints[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Compute essential matrix and recover pose\n",
    "    E, mask = cv2.findEssentialMat(src_pts, dst_pts)\n",
    "    \n",
    "    if E is None or E.shape != (3, 3):\n",
    "        print(\"Essential matrix could not be computed.\")\n",
    "        print(E)\n",
    "        return None, None\n",
    "\n",
    "    # Use only inliers for recoverPose\n",
    "    try:\n",
    "        _, R, t, mask_pose = cv2.recoverPose(E, src_pts, dst_pts)\n",
    "    except cv2.error as e:\n",
    "        print(i)\n",
    "        print(good_matches)\n",
    "    \n",
    "\n",
    "    return R, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "trajectory = []\n",
    "landmarks = []\n",
    "prev_keypoints = None\n",
    "prev_descriptors = None\n",
    "prev_pose = np.eye(4)  # Initial pose (identity matrix)\n",
    "\n",
    "for index in range(len(synchronized_df) - 1):\n",
    "    curr_image_path = synchronized_df.iloc[index + 1]['image_path']\n",
    "    \n",
    "    # Extract features from current and previous images\n",
    "    curr_keypoints, curr_descriptors = extract_features(curr_image_path)\n",
    "    \n",
    "    if prev_keypoints is not None:\n",
    "        # Estimate motion using visual odometry and IMU data\n",
    "        R, t = compute_pose(prev_keypoints, prev_descriptors, curr_keypoints, curr_descriptors, index)\n",
    "        \n",
    "        if R is not None and t is not None:\n",
    "            # Update trajectory using IMU data for better accuracy\n",
    "            imu_roll = synchronized_df.iloc[index + 1]['imu_roll']\n",
    "            imu_pitch = synchronized_df.iloc[index + 1]['imu_pitch']\n",
    "            imu_yaw = synchronized_df.iloc[index + 1]['imu_yaw']\n",
    "\n",
    "            # Convert IMU angles to rotation matrix (assuming small angles)\n",
    "            imu_rotation_matrix = cv2.Rodrigues(np.array([np.radians(imu_roll), np.radians(imu_pitch), np.radians(imu_yaw)]))[0]\n",
    "\n",
    "            # Combine visual odometry with IMU data (simple integration)\n",
    "            combined_rotation_matrix = imu_rotation_matrix @ R\n",
    "            combined_translation_vector = t.flatten() + prev_pose[:3, :3] @ np.array([synchronized_df.iloc[index + 1]['imu_ax'], \n",
    "                                                                                       synchronized_df.iloc[index + 1]['imu_ay'], \n",
    "                                                                                       synchronized_df.iloc[index + 1]['imu_az']])\n",
    "\n",
    "            # Update pose\n",
    "            current_pose = np.eye(4)\n",
    "            current_pose[:3, :3] = combined_rotation_matrix\n",
    "            current_pose[:3, 3] = combined_translation_vector\n",
    "            \n",
    "            trajectory.append(current_pose[:3, 3])  # Store position\n",
    "\n",
    "            # Add landmarks (e.g., if you detect new features)\n",
    "            for kp in curr_keypoints:\n",
    "                landmarks.append((kp.pt[0], kp.pt[1]))  # Store landmark positions\n",
    "\n",
    "    # Update previous keypoints and descriptors for next iteration\n",
    "    prev_keypoints = curr_keypoints\n",
    "    prev_descriptors = curr_descriptors\n",
    "\n",
    "# Convert trajectory to numpy array for visualization\n",
    "trajectory = np.array(trajectory)\n",
    "\n",
    "# Visualization of Trajectory and Landmarks\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(trajectory[:, 0], trajectory[:, 1], label='Camera Trajectory')\n",
    "plt.scatter(*zip(*landmarks), color='red', s=5)  # Plot landmarks in red\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.title('Camera Trajectory with Landmarks')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
