{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graphslam.graph import Graph\n",
    "from graphslam.vertex import Vertex\n",
    "from graphslam.edge.edge_odometry import EdgeOdometry\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader:\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.image_files = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
    "        self.image_files.sort()  # Ensure images are in order\n",
    "        self.current_index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_index >= len(self.image_files):\n",
    "            raise StopIteration\n",
    "        \n",
    "        image_path = os.path.join(self.folder_path, self.image_files[self.current_index])\n",
    "        image = cv2.imread(image_path)\n",
    "        self.current_index += 1\n",
    "        return image\n",
    "\n",
    "# Usage\n",
    "folder_path='sample_data/Room_back_home-2024-12-29_19-50-26/'\n",
    "folder_path_img = folder_path+'/Camera'\n",
    "image_loader = ImageLoader(folder_path_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyro = pd.read_csv(folder_path+'Gyroscope.csv')\n",
    "gyro['time_diff_s'] = gyro['time'].diff().fillna(0) / 1e9\n",
    "gyro['roll'] = (gyro['x']*gyro['time_diff_s']).cumsum()\n",
    "gyro['pitch'] = (gyro['y']*gyro['time_diff_s']).cumsum()\n",
    "gyro['yaw'] = (gyro['z']*gyro['time_diff_s']).cumsum()\n",
    "gyro.drop(['x','y','z'],axis=1,inplace=True)\n",
    "\n",
    "acc = pd.read_csv(folder_path+'/Accelerometer.csv')\n",
    "\n",
    "motion = pd.merge(gyro, acc, on=['time','seconds_elapsed'],how='inner')\n",
    "motion.rename(columns={'x': 'ax','y': 'ay','z': 'az'}, inplace=True)\n",
    "motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1731164816467        in ms\n",
    "#1731164816433211400  in ns\n",
    "image_filenames = sorted(os.listdir(folder_path_img))[1:-1]\n",
    "image_timestamps = [float(filename.split('.')[0]) for filename in image_filenames] \n",
    "\n",
    "def synchronize_data(imu_data, image_timestamps):\n",
    "    synchronized_data = []\n",
    "    for img_time in image_timestamps:\n",
    "        # Find closest IMU timestamp\n",
    "        closest_imu_index = (np.abs(imu_data['time'] - img_time*1e6)).argmin()\n",
    "        synchronized_data.append({\n",
    "            'image_time': img_time,\n",
    "            'imu_roll': imu_data.iloc[closest_imu_index]['roll'],\n",
    "            'imu_pitch': imu_data.iloc[closest_imu_index]['pitch'],\n",
    "            'imu_yaw': imu_data.iloc[closest_imu_index]['yaw'],\n",
    "            'imu_ax': imu_data.iloc[closest_imu_index]['ax'],\n",
    "            'imu_ay': imu_data.iloc[closest_imu_index]['ay'],\n",
    "            'imu_az': imu_data.iloc[closest_imu_index]['az'],\n",
    "            'image_path': os.path.join(folder_path_img, image_filenames[image_timestamps.index(img_time)])\n",
    "        })\n",
    "    return pd.DataFrame(synchronized_data)\n",
    "\n",
    "synchronized_df = synchronize_data(motion, image_timestamps)\n",
    "synchronized_df['time_diff_s'] = synchronized_df['image_time'].diff().fillna(0) / 1e3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synchronized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define slam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pose Estimation with IMU Integration\n",
    "def compute_pose(prev_keypoints, prev_descriptors, curr_keypoints, curr_descriptors, i):\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = matcher.match(prev_descriptors, curr_descriptors)\n",
    "\n",
    "    # Filter matches to get only good matches\n",
    "    good_matches = [m for m in matches if m.distance < 50]  # Adjust threshold as necessary\n",
    "\n",
    "    if len(good_matches) < 5:\n",
    "        print(\"Not enough matches found.\",i)\n",
    "        return None, None\n",
    "\n",
    "    src_pts = np.float32([prev_keypoints[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([curr_keypoints[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Compute essential matrix and recover pose\n",
    "    E, mask = cv2.findEssentialMat(src_pts, dst_pts)\n",
    "    \n",
    "    if E is None or E.shape != (3, 3):\n",
    "        print(\"Essential matrix could not be computed.\")\n",
    "        print(E)\n",
    "        return None, None\n",
    "\n",
    "    # Use only inliers for recoverPose\n",
    "    try:\n",
    "        _, R, t, mask_pose = cv2.recoverPose(E, src_pts, dst_pts)\n",
    "    except cv2.error as e:\n",
    "        print(i)\n",
    "        print(good_matches)\n",
    "    \n",
    "\n",
    "    return R, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "trajectory = []\n",
    "landmarks = []\n",
    "prev_keypoints = None\n",
    "prev_descriptors = None\n",
    "prev_pose = np.eye(4)  # Initial pose (identity matrix)\n",
    "\n",
    "for index in range(len(synchronized_df) - 1):\n",
    "    curr_image_path = synchronized_df.iloc[index + 1]['image_path']\n",
    "    \n",
    "    # Extract features from current and previous images\n",
    "    curr_keypoints, curr_descriptors = extract_features(curr_image_path)\n",
    "    \n",
    "    if prev_keypoints is not None:\n",
    "        # Estimate motion using visual odometry and IMU data\n",
    "        R, t = compute_pose(prev_keypoints, prev_descriptors, curr_keypoints, curr_descriptors, index)\n",
    "        \n",
    "        if R is not None and t is not None:\n",
    "            # Update trajectory using IMU data for better accuracy\n",
    "            imu_roll = synchronized_df.iloc[index + 1]['imu_roll']\n",
    "            imu_pitch = synchronized_df.iloc[index + 1]['imu_pitch']\n",
    "            imu_yaw = synchronized_df.iloc[index + 1]['imu_yaw']\n",
    "\n",
    "            # Convert IMU angles to rotation matrix (assuming small angles)\n",
    "            imu_rotation_matrix = cv2.Rodrigues(np.array([np.radians(imu_roll), np.radians(imu_pitch), np.radians(imu_yaw)]))[0]\n",
    "\n",
    "            # Combine visual odometry with IMU data (simple integration)\n",
    "            combined_rotation_matrix = imu_rotation_matrix @ R\n",
    "            combined_translation_vector = t.flatten() + prev_pose[:3, :3] @ np.array([synchronized_df.iloc[index + 1]['imu_ax'], \n",
    "                                                                                       synchronized_df.iloc[index + 1]['imu_ay'], \n",
    "                                                                                       synchronized_df.iloc[index + 1]['imu_az']])\n",
    "\n",
    "            # Update pose\n",
    "            current_pose = np.eye(4)\n",
    "            current_pose[:3, :3] = combined_rotation_matrix\n",
    "            current_pose[:3, 3] = combined_translation_vector\n",
    "            \n",
    "            trajectory.append(current_pose[:3, 3])  # Store position\n",
    "\n",
    "            # Add landmarks (e.g., if you detect new features)\n",
    "            for kp in curr_keypoints:\n",
    "                landmarks.append((kp.pt[0], kp.pt[1]))  # Store landmark positions\n",
    "\n",
    "    # Update previous keypoints and descriptors for next iteration\n",
    "    prev_keypoints = curr_keypoints\n",
    "    prev_descriptors = curr_descriptors\n",
    "\n",
    "# Convert trajectory to numpy array for visualization\n",
    "trajectory = np.array(trajectory)\n",
    "\n",
    "# Visualization of Trajectory and Landmarks\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(trajectory[:, 0], trajectory[:, 1], label='Camera Trajectory')\n",
    "plt.scatter(*zip(*landmarks), color='red', s=5)  # Plot landmarks in red\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.title('Camera Trajectory with Landmarks')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reconstruct trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Pose Estimation from IMU Data\n",
    "def compute_pose_from_imu(roll, pitch, yaw, ax,ay,az, dt):\n",
    "    # Create rotation matrix from Euler angles\n",
    "    R_x = np.array([[1, 0, 0],\n",
    "                    [0, np.cos(roll), -np.sin(roll)],\n",
    "                    [0, np.sin(roll), np.cos(roll)]])\n",
    "    \n",
    "    R_y = np.array([[np.cos(pitch), 0, np.sin(pitch)],\n",
    "                    [0, 1, 0],\n",
    "                    [-np.sin(pitch), 0, np.cos(pitch)]])\n",
    "    \n",
    "    R_z = np.array([[np.cos(yaw), -np.sin(yaw), 0],\n",
    "                    [np.sin(yaw), np.cos(yaw), 0],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "    # Combined rotation matrix\n",
    "    R = R_z @ R_y @ R_x\n",
    "\n",
    "    # Integrate acceleration to get velocity\n",
    "    velocity_change = np.array([ax * dt, ay * dt, az * dt])\n",
    "    \n",
    "    # Transform velocity change into global frame using rotation matrix\n",
    "    global_velocity_change = R @ velocity_change\n",
    "    \n",
    "    return R, global_velocity_change\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Initialize GraphSLAM and Variables\n",
    "from graphslam.vertex import Vertex\n",
    "from graphslam.edge import Edge\n",
    "\n",
    "edges = []\n",
    "vertices = []\n",
    "g = Graph(edges, vertices)  # Create a new graph instance\n",
    "landmarks = {}\n",
    "trajectory = []\n",
    "dt = 0.1  # Example time step (assuming constant time between frames)\n",
    "velocity = np.zeros(3)  # Initialize velocity\n",
    "\n",
    "for index in range(len(synchronized_df)):\n",
    "    roll = synchronized_df.iloc[index]['imu_roll']\n",
    "    pitch = synchronized_df.iloc[index]['imu_pitch']\n",
    "    yaw = synchronized_df.iloc[index]['imu_yaw']\n",
    "    \n",
    "    # Get IMU acceleration data\n",
    "    ax = synchronized_df.iloc[index]['imu_ax']\n",
    "    ay = synchronized_df.iloc[index]['imu_ay']\n",
    "    az = synchronized_df.iloc[index]['imu_az']\n",
    "\n",
    "    # Compute pose from IMU data\n",
    "    R, velocity_change = compute_pose_from_imu(roll, pitch, yaw, ax, ay, az, dt)\n",
    "    \n",
    "    # Update velocity based on acceleration (integrate)\n",
    "    velocity += velocity_change\n",
    "    \n",
    "    if index == 0:\n",
    "        current_position = np.zeros(3)  # Initial position at origin\n",
    "    else:\n",
    "        current_position += velocity * dt  # Integrate velocity to get position\n",
    "\n",
    "    # Create vertex for current pose\n",
    "    vertex = Vertex(index, current_position)\n",
    "    vertices.append(vertex)\n",
    "    \n",
    "    # Create edge between consecutive poses\n",
    "    if index > 0:\n",
    "        edge = Edge(vertices[index-1], vertex, velocity_change * dt)\n",
    "        edges.append(edge)\n",
    "\n",
    "    trajectory.append(current_position)\n",
    "\n",
    "    # Extract features from the current image\n",
    "    curr_image_path = synchronized_df.iloc[index]['image_path']\n",
    "    img = cv2.imread(curr_image_path)\n",
    "    \n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    orb = cv2.ORB_create()\n",
    "    \n",
    "    keypoints, descriptors = orb.detectAndCompute(gray_img, None)\n",
    "\n",
    "    # Create landmarks based on detected keypoints (for simplicity)\n",
    "    for kp in keypoints:\n",
    "        landmark_id = len(landmarks) + len(synchronized_df) + 1\n",
    "        \n",
    "        if landmark_id not in landmarks:\n",
    "            landmarks[landmark_id] = (kp.pt[0], kp.pt[1], current_position)  # Store landmark with its position\n",
    "            \n",
    "            # Add landmark as a vertex in the optimizer (assuming Z is height or depth estimation)\n",
    "            g.add_landmark(landmark_id,\n",
    "                           np.array([kp.pt[0], kp.pt[1], current_position[2]])) \n",
    "\n",
    "            # Add edge between current pose and landmark (assuming we have observations)\n",
    "            g.add_edge(index, landmark_id)  # Edge from pose to landmark\n",
    "\n",
    "# Optimize the graph after processing all frames\n",
    "g.optimize()  # Perform optimization\n",
    "\n",
    "# Convert trajectory to numpy array for visualization\n",
    "trajectory = np.array(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "# Create a scatter plot for the trajectory\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=trajectory[:,0],\n",
    "    y=trajectory[:,1],\n",
    "    z=trajectory[:,2],\n",
    "    mode='lines',\n",
    "    line=dict(color='blue', width=2),\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Trajectory Plot with Grid',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='X Position', gridcolor='lightgray', showgrid=True),\n",
    "        yaxis=dict(title='Y Position', gridcolor='lightgray', showgrid=True),\n",
    "        zaxis=dict(title='Z Position', gridcolor='lightgray', showgrid=True),\n",
    "        aspectmode='cube'  # Optional: Keep the aspect ratio equal\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40)  # Adjust margins for better visibility\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
