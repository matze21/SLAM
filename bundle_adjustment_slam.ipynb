{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time \n",
    "import g2o \n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#from g2o import LinearSolverCSparseSE3, BlockSolverSE3_3, VertexSE3, EdgeSE3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path='sample_data/Room_back_home-2024-12-29_19-50-26/'\n",
    "folder_path_img = folder_path+'/Camera'\n",
    "\n",
    "gyro = pd.read_csv(folder_path+'Gyroscope.csv')\n",
    "gyro['time_diff_s'] = gyro['time'].diff().fillna(0) / 1e9\n",
    "gyro['roll'] = (gyro['x']*gyro['time_diff_s']).cumsum()\n",
    "gyro['pitch'] = (gyro['y']*gyro['time_diff_s']).cumsum()\n",
    "gyro['yaw'] = (gyro['z']*gyro['time_diff_s']).cumsum()\n",
    "gyro.drop(['x','y','z'],axis=1,inplace=True)\n",
    "\n",
    "acc = pd.read_csv(folder_path+'/Accelerometer.csv')\n",
    "\n",
    "motion = pd.merge(gyro, acc, on=['time','seconds_elapsed'],how='inner')\n",
    "motion.rename(columns={'x': 'ax','y': 'ay','z': 'az'}, inplace=True)\n",
    "\n",
    "\n",
    "image_filenames = sorted(os.listdir(folder_path_img))[1:-1]\n",
    "image_timestamps = [float(filename.split('.')[0]) for filename in image_filenames] \n",
    "\n",
    "def synchronize_data(imu_data, image_timestamps):\n",
    "    synchronized_data = []\n",
    "    for img_time in image_timestamps:\n",
    "        # Find closest IMU timestamp\n",
    "        closest_imu_index = (np.abs(imu_data['time'] - img_time*1e6)).argmin()\n",
    "        synchronized_data.append({\n",
    "            'image_time': img_time,\n",
    "            'roll': imu_data.iloc[closest_imu_index]['roll'],\n",
    "            'pitch': imu_data.iloc[closest_imu_index]['pitch'],\n",
    "            'yaw': imu_data.iloc[closest_imu_index]['yaw'],\n",
    "            'ax': imu_data.iloc[closest_imu_index]['ax'],\n",
    "            'ay': imu_data.iloc[closest_imu_index]['ay'],\n",
    "            'az': imu_data.iloc[closest_imu_index]['az'],\n",
    "            'image_path': os.path.join(folder_path_img, image_filenames[image_timestamps.index(img_time)])\n",
    "        })\n",
    "    return pd.DataFrame(synchronized_data)\n",
    "\n",
    "synchronized_synchronized_df = synchronize_data(motion, image_timestamps)\n",
    "synchronized_synchronized_df['time_diff_s'] = synchronized_synchronized_df['image_time'].diff().fillna(0) / 1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    return cv2.imread(path)\n",
    "\n",
    "def extract(img, nPoints):\n",
    "    \"\"\" \n",
    "    extract features of an image\n",
    "    \"\"\"\n",
    "    orb = cv2.ORB_create()\n",
    " \n",
    "    # Detection\n",
    "    pts = cv2.goodFeaturesToTrack(np.mean(img, axis=-1).astype(np.uint8), nPoints, qualityLevel=0.01, minDistance=10)\n",
    "\n",
    " \n",
    "    # Extract key points\n",
    "    kps = [cv2.KeyPoint(f[0][0], f[0][1], 20) for f in pts]\n",
    "    kps, des = orb.compute(img, kps)\n",
    " \n",
    "    return np.array([(kp.pt[0], kp.pt[1]) for kp in kps]), des\n",
    "\n",
    "def add_ones(x):\n",
    "    \"\"\" \n",
    "    helper function to add ones to have right format of normalized coordinates (TODO: understand better)\n",
    "    \"\"\"\n",
    "    # creates homogenious coordinates given the point x\n",
    "    return np.concatenate([x, np.ones((x.shape[0], 1))], axis=1)\n",
    "\n",
    "def normalize(Kinv, pts):\n",
    "    \"\"\"\n",
    "    transform image coordinates to normalized coordinates\n",
    "    \"\"\"\n",
    "    # The inverse camera intrinsic matrix ùêæ^(‚àí1) transforms 2D homogeneous points \n",
    "    # from pixel coordinates to normalized image coordinates. \n",
    "    return np.dot(Kinv, add_ones(pts).T).T[:, 0:2]\n",
    "\n",
    "def un_normalize(K, normalized_pts):\n",
    "    \"\"\"\n",
    "    Transform normalized coordinates back to image coordinates\n",
    "    \"\"\"\n",
    "    # Add homogeneous coordinate\n",
    "    homogeneous_pts = add_ones(normalized_pts)\n",
    "    \n",
    "    # Apply camera intrinsic matrix K\n",
    "    image_pts = np.dot(K, homogeneous_pts.T).T\n",
    "    \n",
    "    # Remove homogeneous coordinate and return 2D image coordinates\n",
    "    return image_pts[:, :2]\n",
    "\n",
    "class Frame(object):\n",
    "    \"\"\" \n",
    "    Class that has all the frame data\n",
    "    \"\"\"\n",
    "    def __init__(self, img, K, id, pointsPerImg):\n",
    "        self.id = id   # unique identifier\n",
    "        self.K = K     # Intrinsic camera matrix\n",
    "        self.Kinv = np.linalg.inv(self.K)  # Inverse of the intrinsic camera matrix\n",
    " \n",
    "        pts, self.des = extract(img, pointsPerImg)             # Extract feature points and descriptors from the image\n",
    "        self.pts = normalize(self.Kinv, pts)     # Normalizes feature points to normalized coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useg2o = False\n",
    "\n",
    "class UniquePointsFullListMatching(object):\n",
    "    \"\"\" \n",
    "    this class tracks all unique points in entire frame, it consists of 3 index parallel lists\n",
    "    descriptor: list of unique descriptors in entire sequence\n",
    "    frameIds:   list of frame ids (list of lists), index parallel to descriptor (one descriptor multiple frame ids)\n",
    "    normPoints: list of normalized points per frame (list of lists), also index parallel to descriptor (one descriptor, multiple frames with a point per frame)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.descriptor = [] # (descriptor, [frame_ids])\n",
    "        self.frameIds   = []\n",
    "        self.normPoints = [] #normalized point per frame id\n",
    "        self.initial3dEstimates = []\n",
    "        self.cameraPosition = [] # x,y,z\n",
    "        self.cameraVelocity = []\n",
    "        self.cameraAngle = []    # roll, pitch, yaw\n",
    "        if useg2o:\n",
    "            self.optimizer = g2o.SparseOptimizer()\n",
    "            solver = g2o.BlockSolverSE3(g2o.LinearSolverCSparseSE3())\n",
    "            solver = g2o.OptimizationAlgorithmLevenberg(solver)\n",
    "            self.optimizer.set_algorithm(solver)\n",
    "        self.K = np.array([[730, 0, 620], [0, 730, 360], [0, 0, 1]])\n",
    "        self.frame_id = 0\n",
    "\n",
    "    def processFrame(self, row):\n",
    "        img = load_image(row.image_path)\n",
    "        f = Frame(img, self.K, self.frame_id, 50)\n",
    "        self.frame_id += 1\n",
    "\n",
    "        self.addImuData2D(row, f)\n",
    "\n",
    "        if( not self.descriptor):\n",
    "            for idx, des in enumerate(f.des):\n",
    "                self.addNewPoint(des, f.id, f.pts[idx])\n",
    "        else:\n",
    "            self.calcAssociations(f)\n",
    "\n",
    "    # frame idx is the index of the frame pose\n",
    "    def addImuData2D(self, row, f):\n",
    "        frameId = f.id\n",
    "        prevFrameId = frameId - 1\n",
    "        # assume data is 2d only for now (no motion in y)\n",
    "        if not self.cameraPosition:\n",
    "            vx = 0\n",
    "            vy = 0\n",
    "            vz = 0\n",
    "            x = 0\n",
    "            y = 0\n",
    "            z = 0\n",
    "        else:\n",
    "            vx,vy,vz = self.cameraVelocity[prevFrameId]\n",
    "            x,y,z = self.cameraPosition[prevFrameId]\n",
    "\n",
    "        dvx = row.ax * row.time_diff_s\n",
    "        dvy = 0\n",
    "        dvz = row.az * row.time_diff_s\n",
    "\n",
    "        new_velocity = [vx + dvx, vy+dvy, vz + dvz]\n",
    "        dx = new_velocity[0] * row.time_diff_s\n",
    "        dy = new_velocity[1] * row.time_diff_s\n",
    "        dz = new_velocity[2] * row.time_diff_s\n",
    "        new_position = [x + dx, y+dy, z + dz]\n",
    "\n",
    "        self.cameraVelocity.append(new_velocity)\n",
    "        self.cameraPosition.append(new_position)\n",
    "        self.cameraAngle.append([0, row.pitch,0])\n",
    "\n",
    "        if useg2o:\n",
    "            pose = g2o.SE3Quat()\n",
    "            pose.set_translation(np.array(new_position))\n",
    "            pose.set_rotation(g2o.Quaternion(np.array([0, row.pitch, 0])))\n",
    "            self.add_pose_vertex(pose, frameId)\n",
    "\n",
    "            # calc relative pose\n",
    "            if not self.cameraPosition:\n",
    "                dpitch = row.pitch - self.cameraAngle[prevFrameId][0]\n",
    "\n",
    "                # Create relative pose\n",
    "                relative_pose = g2o.SE3Quat()\n",
    "                relative_pose.set_translation(np.array([dx, 0, dz]))\n",
    "                relative_pose.set_rotation(g2o.Quaternion(np.array([0, dpitch, 0])))\n",
    "                information = np.identity(6)  # Example information matrix\n",
    "                self.add_imu_edge(prevFrameId, frameId, relative_pose, information)\n",
    "\n",
    "        \n",
    "    def calcAssociations(self, f):\n",
    "        # The code performs k-nearest neighbors matching on feature descriptors\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "        matches = bf.knnMatch(np.array(self.descriptor), f.des, k=2)    \n",
    "\n",
    "        matched_indices = set()\n",
    "        for i, (m, n) in enumerate(matches):\n",
    "            if m.distance < 0.1 * n.distance:\n",
    "                p1 = self.normPoints[m.queryIdx][-1]\n",
    "                p2 = f.pts[m.trainIdx]\n",
    "\n",
    "                self.associate(m.queryIdx, f.id, p2)\n",
    "                matched_indices.add(m.trainIdx)\n",
    "\n",
    "        # Process unmatched points\n",
    "        for i in range(len(f.des)):\n",
    "            if i not in matched_indices:\n",
    "                # Add new point\n",
    "                self.addNewPoint(f.des[i],f.id, f.pts[i]) \n",
    "        \n",
    "\n",
    "\n",
    "    def associate(self, uniquePtIdx, frameId, newPoint):\n",
    "        ptCount = len(self.normPoints[uniquePtIdx])\n",
    "        self.frameIds[uniquePtIdx].append(frameId)  # add new frameid to associated point\n",
    "        self.normPoints[uniquePtIdx].append(newPoint)  # add new normalized point to associated point\n",
    "\n",
    "        # Triangulate the 3D point\n",
    "        if ptCount == 1: # triangulate if this is the second frame\n",
    "            p1 = self.normPoints[uniquePtIdx][0]\n",
    "            pt3d = self.triangulate(self.frameIds[uniquePtIdx][0], frameId, p1, newPoint)\n",
    "            self.initial3dEstimates[uniquePtIdx] = pt3d\n",
    "            if useg2o:\n",
    "                self.add_landmark_vertex(pt3d, uniquePtIdx)\n",
    "\n",
    "        if ptCount > 1: # add visual edge if this is the third frame\n",
    "            if useg2o:\n",
    "                self.add_visual_edge(frameId, uniquePtIdx, newPoint, np.identity(2))\n",
    "\n",
    "    def triangulate(self, frameId1, frameId2, p1, p2):\n",
    "        R1 = cv2.Rodrigues(np.array(self.cameraAngle[frameId1]))[0]\n",
    "        t1 = np.array(self.cameraPosition[frameId1])\n",
    "        R2 = cv2.Rodrigues(np.array(self.cameraAngle[frameId2]))[0]\n",
    "        t2 = np.array(self.cameraPosition[frameId1])\n",
    "\n",
    "        P1 = np.hstack((R1, t1[:, None]))  # 3x4 projection matrix for first camera\n",
    "        P2 = np.hstack((R2, t2[:, None]))  # 3x4 projection matrix for second camera\n",
    "\n",
    "        # Ensure p1 and p2 are in the correct shape (3xN)\n",
    "        p1 = np.array(p1).T if p1.shape[0] != 3 else p1\n",
    "        p2 = np.array(p2).T if p2.shape[0] != 3 else p2\n",
    "\n",
    "        # Triangulate the 3D point\n",
    "        points_4d = cv2.triangulatePoints(P1, P2, p1[:2], p2[:2])\n",
    "\n",
    "        # Convert from homogeneous to 3D coordinates\n",
    "        points_3d = points_4d[:3] / points_4d[3]\n",
    "\n",
    "        return points_3d.T\n",
    "\n",
    "    def addNewPoint(self, des, frameId, point):\n",
    "        self.descriptor.append(des)\n",
    "        self.frameIds.append([frameId])\n",
    "        self.normPoints.append([point])\n",
    "        self.initial3dEstimates.append(None)\n",
    "\n",
    "    def add_pose_vertex(self, pose, pose_id):\n",
    "        v_se3 = g2o.VertexSE3()\n",
    "        v_se3.set_id(pose_id)\n",
    "        v_se3.set_estimate(pose)\n",
    "        self.optimizer.add_vertex(v_se3)\n",
    "\n",
    "    def add_landmark_vertex(self, point, landmark_id):\n",
    "        v_point = g2o.VertexSBAPointXYZ()\n",
    "        v_point.set_id(landmark_id)\n",
    "        v_point.set_estimate(point)\n",
    "        v_point.set_marginalized(True)\n",
    "        self.optimizer.add_vertex(v_point)\n",
    "\n",
    "    def add_imu_edge(self, pose_id1, pose_id2, relative_pose, information):\n",
    "        edge = g2o.EdgeSE3()\n",
    "        edge.set_vertex(0, self.optimizer.vertex(pose_id1))\n",
    "        edge.set_vertex(1, self.optimizer.vertex(pose_id2))\n",
    "        edge.set_measurement(relative_pose)\n",
    "        edge.set_information(information)\n",
    "        self.optimizer.add_edge(edge)\n",
    "\n",
    "    def add_visual_edge(self, pose_id, landmark_id, imagePoint, information):\n",
    "        \"\"\"\n",
    "        add an image point to the optimizer, pose_id is the camera pose, landmark_id is the 3D point estimate\n",
    "        \"\"\"\n",
    "        edge = g2o.EdgeProjectXYZ2UV()\n",
    "        edge.set_vertex(0, self.optimizer.vertex(landmark_id))\n",
    "        edge.set_vertex(1, self.optimizer.vertex(pose_id))\n",
    "        edge.set_measurement(imagePoint)\n",
    "        edge.set_information(information)\n",
    "        self.optimizer.add_edge(edge)\n",
    "\n",
    "    def optimize(self, iterations=10):\n",
    "        self.optimizer.initialize_optimization()\n",
    "        self.optimizer.optimize(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run association\n",
    "uniquePts = UniquePointsFullListMatching()\n",
    "K = np.array([[730, 0, 620], [0, 730, 360], [0, 0, 1]])  # Example values\n",
    "\n",
    "for idx, row in synchronized_synchronized_df.iterrows():\n",
    "    uniquePts.processFrame(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the x and z coordinates\n",
    "x_coords = [pt[0] for pt in uniquePts.cameraPosition]\n",
    "z_coords = [pt[2] for pt in uniquePts.cameraPosition]\n",
    "\n",
    "filtered_pts = [pt for pt in uniquePts.initial3dEstimates if pt is not None and -10 <= pt[0][0] <= 70 and -20 <= pt[0][2] <= 20]\n",
    "x_3dEst = [0 if pt is None else pt[0][0] for pt in filtered_pts]\n",
    "z_3dEst = [0 if pt is None else pt[0][2] for pt in filtered_pts]\n",
    "\n",
    "# Create the plot\n",
    "plt.scatter(x_coords, z_coords)\n",
    "plt.scatter(x_3dEst, z_3dEst, colorizer='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Z')\n",
    "plt.title('Camera Positions in X-Z Plane')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pt in uniquePts.initial3dEstimates:\n",
    "    if pt is not None:\n",
    "        print(pt[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
