{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time \n",
    "import g2o \n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path='sample_data/Room_back_home-2024-12-29_19-50-26/'\n",
    "folder_path_img = folder_path+'/Camera'\n",
    "\n",
    "gyro = pd.read_csv(folder_path+'Gyroscope.csv')\n",
    "gyro['time_diff_s'] = gyro['time'].diff().fillna(0) / 1e9\n",
    "gyro['roll'] = (gyro['x']*gyro['time_diff_s']).cumsum()\n",
    "gyro['pitch'] = (gyro['y']*gyro['time_diff_s']).cumsum()\n",
    "gyro['yaw'] = (gyro['z']*gyro['time_diff_s']).cumsum()\n",
    "gyro.drop(['x','y','z'],axis=1,inplace=True)\n",
    "\n",
    "acc = pd.read_csv(folder_path+'/Accelerometer.csv')\n",
    "\n",
    "motion = pd.merge(gyro, acc, on=['time','seconds_elapsed'],how='inner')\n",
    "motion.rename(columns={'x': 'ax','y': 'ay','z': 'az'}, inplace=True)\n",
    "\n",
    "\n",
    "image_filenames = sorted(os.listdir(folder_path_img))[1:-1]\n",
    "image_timestamps = [float(filename.split('.')[0]) for filename in image_filenames] \n",
    "\n",
    "def synchronize_data(imu_data, image_timestamps):\n",
    "    synchronized_data = []\n",
    "    for img_time in image_timestamps:\n",
    "        # Find closest IMU timestamp\n",
    "        closest_imu_index = (np.abs(imu_data['time'] - img_time*1e6)).argmin()\n",
    "        synchronized_data.append({\n",
    "            'image_time': img_time,\n",
    "            'imu_roll': imu_data.iloc[closest_imu_index]['roll'],\n",
    "            'imu_pitch': imu_data.iloc[closest_imu_index]['pitch'],\n",
    "            'imu_yaw': imu_data.iloc[closest_imu_index]['yaw'],\n",
    "            'imu_ax': imu_data.iloc[closest_imu_index]['ax'],\n",
    "            'imu_ay': imu_data.iloc[closest_imu_index]['ay'],\n",
    "            'imu_az': imu_data.iloc[closest_imu_index]['az'],\n",
    "            'image_path': os.path.join(folder_path_img, image_filenames[image_timestamps.index(img_time)])\n",
    "        })\n",
    "    return pd.DataFrame(synchronized_data)\n",
    "\n",
    "synchronized_synchronized_df = synchronize_data(motion, image_timestamps)\n",
    "synchronized_synchronized_df['time_diff_s'] = synchronized_synchronized_df['image_time'].diff().fillna(0) / 1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    return cv2.imread(path)\n",
    "\n",
    "def extract(img, nPoints):\n",
    "    \"\"\" \n",
    "    extract features of an image\n",
    "    \"\"\"\n",
    "    orb = cv2.ORB_create()\n",
    " \n",
    "    # Detection\n",
    "    pts = cv2.goodFeaturesToTrack(np.mean(img, axis=-1).astype(np.uint8), nPoints, qualityLevel=0.01, minDistance=10)\n",
    "\n",
    " \n",
    "    # Extract key points\n",
    "    kps = [cv2.KeyPoint(f[0][0], f[0][1], 20) for f in pts]\n",
    "    kps, des = orb.compute(img, kps)\n",
    " \n",
    "    return np.array([(kp.pt[0], kp.pt[1]) for kp in kps]), des\n",
    "\n",
    "def add_ones(x):\n",
    "    \"\"\" \n",
    "    helper function to add ones to have right format of normalized coordinates (TODO: understand better)\n",
    "    \"\"\"\n",
    "    # creates homogenious coordinates given the point x\n",
    "    return np.concatenate([x, np.ones((x.shape[0], 1))], axis=1)\n",
    "\n",
    "def normalize(Kinv, pts):\n",
    "    \"\"\"\n",
    "    transform image coordinates to normalized coordinates\n",
    "    \"\"\"\n",
    "    # The inverse camera intrinsic matrix ùêæ^(‚àí1) transforms 2D homogeneous points \n",
    "    # from pixel coordinates to normalized image coordinates. \n",
    "    return np.dot(Kinv, add_ones(pts).T).T[:, 0:2]\n",
    "\n",
    "def un_normalize(K, normalized_pts):\n",
    "    \"\"\"\n",
    "    Transform normalized coordinates back to image coordinates\n",
    "    \"\"\"\n",
    "    # Add homogeneous coordinate\n",
    "    homogeneous_pts = add_ones(normalized_pts)\n",
    "    \n",
    "    # Apply camera intrinsic matrix K\n",
    "    image_pts = np.dot(K, homogeneous_pts.T).T\n",
    "    \n",
    "    # Remove homogeneous coordinate and return 2D image coordinates\n",
    "    return image_pts[:, :2]\n",
    "\n",
    "class Frame(object):\n",
    "    \"\"\" \n",
    "    Class that has all the frame data\n",
    "    \"\"\"\n",
    "    def __init__(self, img, K, id, pointsPerImg):\n",
    "        self.id = id   # unique identifier\n",
    "        self.K = K     # Intrinsic camera matrix\n",
    "        self.Kinv = np.linalg.inv(self.K)  # Inverse of the intrinsic camera matrix\n",
    " \n",
    "        pts, self.des = extract(img, pointsPerImg)             # Extract feature points and descriptors from the image\n",
    "        self.pts = normalize(self.Kinv, pts)     # Normalizes feature points to normalized coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniquePointsFullListMatching(object):\n",
    "    \"\"\" \n",
    "    this class tracks all unique points in entire frame, it consists of 3 index parallel lists\n",
    "    descriptor: list of unique descriptors in entire sequence\n",
    "    frameIds:   list of frame ids (list of lists), index parallel to descriptor (one descriptor multiple frame ids)\n",
    "    normPoints: list of normalized points per frame (list of lists), also index parallel to descriptor (one descriptor, multiple frames with a point per frame)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.descriptor = [] # (descriptor, [frame_ids])\n",
    "        self.frameIds   = []\n",
    "        self.normPoints = [] #normalized point per frame id\n",
    "        self.initial3dEstimates = []\n",
    "        self.cameraPosition = [] # x,y,z\n",
    "        self.cameraVelocity = []\n",
    "        self.cameraAngle = []    # roll, pitch, yaw\n",
    "        self.optimizer = g2o.SparseOptimizer()\n",
    "        solver = g2o.BlockSolverSE3(g2o.LinearSolverCSparseSE3())\n",
    "        solver = g2o.OptimizationAlgorithmLevenberg(solver)\n",
    "        self.optimizer.set_algorithm(solver)\n",
    "        self.pose_id = 0\n",
    "        self.landmark_id = 0\n",
    "        self.K = np.array([[730, 0, 620], [0, 730, 360], [0, 0, 1]])\n",
    "\n",
    "    def processFrame(self, row):\n",
    "        f = load_image(row.image_path)\n",
    "        self.addImuData2D(row)\n",
    "\n",
    "        if( not self.descriptor):\n",
    "            for idx, des in enumerate(f.des):\n",
    "                self.addNewPoint(des, f.id, f.pts[idx])\n",
    "        else:\n",
    "            self.calcAssociations(f)\n",
    "\n",
    "    def addImuData2D(self, row):\n",
    "        # assume data is 2d only for now (no motion in y)\n",
    "        if not self.cameraPosition:\n",
    "            vx = 0\n",
    "            vy = 0\n",
    "        else:\n",
    "            idx = len(self.cameraPosition)-1\n",
    "            vx,vy,vz = self.cameraVelocity[idx]\n",
    "            x,y,z = self.cameraPosition[idx]\n",
    "\n",
    "        dvx = row.ax * row.time_diff_s\n",
    "        dvz = row.az * row.time_diff_s\n",
    "\n",
    "        new_velocity = [vx + dvx, vy, vz + dvz]\n",
    "        dx = new_velocity[0] * row.time_diff_s\n",
    "        dz = new_velocity[2] * row.time_diff_s\n",
    "        new_position = [x + dx, y, z + dz]\n",
    "\n",
    "        self.cameraVelocity.append(new_velocity)\n",
    "        self.cameraPosition.append(new_position)\n",
    "        self.cameraAngle.append([0, row.pitch,0])\n",
    "\n",
    "        self.add_pose_vertex(new_position)\n",
    "\n",
    "        # calc relative pose\n",
    "        if not self.cameraPosition:\n",
    "            dpitch = row.pitch - self.cameraAngle[idx][0]\n",
    "\n",
    "            # Create relative pose\n",
    "            relative_pose = g2o.SE3Quat()\n",
    "            relative_pose.set_translation(np.array([dx, 0, dz]))\n",
    "            relative_pose.set_rotation(g2o.Quaternion(np.array([0, dpitch, 0])))\n",
    "            information = np.identity(6)  # Example information matrix\n",
    "            self.add_imu_edge(idx, idx + 1, relative_pose, information)\n",
    "\n",
    "        \n",
    "    def calcAssociations(self, f):\n",
    "        # The code performs k-nearest neighbors matching on feature descriptors\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "        matches = bf.knnMatch(np.array(self.descriptor), f.des, k=2)    \n",
    "\n",
    "        matched_indices = set()\n",
    "        for i, (m, n) in enumerate(matches):\n",
    "            if m.distance < 0.5 * n.distance:\n",
    "                p1 = self.normPoints[m.queryIdx][-1]\n",
    "                p2 = f.pts[m.trainIdx]\n",
    "\n",
    "                if np.linalg.norm((p1-p2)) < 0.1:\n",
    "                    self.associate(m.queryIdx, f.id, p2)\n",
    "                    matched_indices.add(m.trainIdx)\n",
    "\n",
    "        # Process unmatched points\n",
    "        for i in range(len(f.des)):\n",
    "            if i not in matched_indices:\n",
    "                # Add new point\n",
    "                self.addNewPoint(f.des[i],f.id, f.pts[i]) \n",
    "        \n",
    "    def triangulate(self, frameId1, frameId2, p1, p2):\n",
    "        R1 = cv2.Rodrigues(np.array(self.cameraAngle[frameId1]))[0]\n",
    "        t1 = np.array(self.cameraPosition[frameId1])\n",
    "        R2 = cv2.Rodrigues(np.array(self.cameraAngle[frameId2]))[0]\n",
    "        t2 = np.array(self.cameraPosition[frameId1])\n",
    "\n",
    "        # Compute the essential matrix\n",
    "        E = np.hstack((R2.dot(R1.T), t2[:, None] - R2.dot(R1.T).dot(t1)[:, None]))\n",
    "\n",
    "        # Triangulate the 3D point\n",
    "        return cv2.triangulatePoints(E, p1, p2)\n",
    "\n",
    "\n",
    "\n",
    "    def associate(self, uniquePtIdx, frameId, newPoint):\n",
    "        self.frameIds[uniquePtIdx].append(frameId)  # add new frameid to associated point\n",
    "        self.normPoints[uniquePtIdx].append(newPoint)  # add new normalized point to associated point\n",
    "\n",
    "    def addNewPoint(self, des, frameId, point):\n",
    "        self.descriptor.append(des)\n",
    "        self.frameIds.append([frameId])\n",
    "        self.normPoints.append([point])\n",
    "\n",
    "    def add_pose_vertex(self, pose):\n",
    "        v_se3 = g2o.VertexSE3()\n",
    "        v_se3.set_id(self.pose_id)\n",
    "        v_se3.set_estimate(pose)\n",
    "        self.optimizer.add_vertex(v_se3)\n",
    "        self.pose_id += 1\n",
    "\n",
    "    def add_landmark_vertex(self, point):\n",
    "        v_point = g2o.VertexSBAPointXYZ()\n",
    "        v_point.set_id(self.landmark_id)\n",
    "        v_point.set_estimate(point)\n",
    "        v_point.set_marginalized(True)\n",
    "        self.optimizer.add_vertex(v_point)\n",
    "        self.landmark_id += 1\n",
    "\n",
    "    def add_imu_edge(self, pose_id1, pose_id2, relative_pose, information):\n",
    "        edge = g2o.EdgeSE3()\n",
    "        edge.set_vertex(0, self.optimizer.vertex(pose_id1))\n",
    "        edge.set_vertex(1, self.optimizer.vertex(pose_id2))\n",
    "        edge.set_measurement(relative_pose)\n",
    "        edge.set_information(information)\n",
    "        self.optimizer.add_edge(edge)\n",
    "\n",
    "    def add_visual_edge(self, pose_id, landmark_id, imagePoint, information):\n",
    "        \"\"\"\n",
    "        add an image point to the optimizer, pose_id is the camera pose, landmark_id is the 3D point estimate\n",
    "        \"\"\"\n",
    "        edge = g2o.EdgeProjectXYZ2UV()\n",
    "        edge.set_vertex(0, self.optimizer.vertex(landmark_id))\n",
    "        edge.set_vertex(1, self.optimizer.vertex(pose_id))\n",
    "        edge.set_measurement(imagePoint)\n",
    "        edge.set_information(information)\n",
    "        self.optimizer.add_edge(edge)\n",
    "\n",
    "    def optimize(self, iterations=10):\n",
    "        self.optimizer.initialize_optimization()\n",
    "        self.optimizer.optimize(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slam = UniquePointsFullListMatching()\n",
    "\n",
    "\n",
    "# Add landmarks using visual features\n",
    "for feature in visual_features:\n",
    "    point = triangulate_point(feature)\n",
    "    slam.add_landmark_vertex(point)\n",
    "\n",
    "# Add edges for IMU data\n",
    "for i in range(len(imu_dataset) - 1):\n",
    "    relative_pose = compute_relative_pose(imu_dataset[i], imu_dataset[i + 1])\n",
    "    information = np.identity(6)  # Example information matrix\n",
    "    slam.add_imu_edge(i, i + 1, relative_pose, information)\n",
    "\n",
    "# Add edges for visual features\n",
    "for imagePoint in visual_observations:\n",
    "    pose_id = imagePoint.pose_id\n",
    "    landmark_id = imagePoint.landmark_id\n",
    "    measurement = imagePoint.measurement\n",
    "    information = np.identity(2)  # Example information matrix\n",
    "    slam.add_visual_edge(pose_id, landmark_id, measurement, information)\n",
    "\n",
    "# Optimize the graph\n",
    "slam.optimize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
